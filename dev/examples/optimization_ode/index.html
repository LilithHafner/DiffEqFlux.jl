<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Optimization of Ordinary Differential Equations Â· DiffEqFlux.jl</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-90474609-3"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-90474609-3', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://diffeqflux.sciml.ai/stable/examples/optimization_ode/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="DiffEqFlux.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">DiffEqFlux.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">DiffEqFlux.jl: Generalized Physics-Informed and Scientific Machine Learning (SciML)</a></li><li><span class="tocitem">Ordinary Differential Equation (ODE) Tutorials</span><ul><li class="is-active"><a class="tocitem" href>Optimization of Ordinary Differential Equations</a><ul class="internal"><li><a class="tocitem" href="#Copy-Paste-Code"><span>Copy-Paste Code</span></a></li><li><a class="tocitem" href="#Explanation"><span>Explanation</span></a></li></ul></li><li><a class="tocitem" href="../stiff_ode_fit/">Parameter Estimation on Highly Stiff Systems</a></li><li><a class="tocitem" href="../neural_ode_sciml/">Neural Ordinary Differential Equations with sciml_train</a></li><li><a class="tocitem" href="../mnist_neural_ode/">GPU-based MNIST Neural ODE Classifier</a></li><li><a class="tocitem" href="../mnist_conv_neural_ode/">Convolutional Neural ODE MNIST Classifier on GPU</a></li><li><a class="tocitem" href="../augmented_neural_ode/">Augmented Neural Ordinary Differential Equations</a></li><li><a class="tocitem" href="../collocation/">Smoothed Collocation for Fast Two-Stage Training</a></li><li><a class="tocitem" href="../neural_gde/">Neural Graph Differential Equations</a></li><li><a class="tocitem" href="../exogenous_input/">Handling Exogenous Input Signals</a></li><li><a class="tocitem" href="../normalizing_flows/">Continuous Normalizing Flows with GalacticOptim.jl</a></li></ul></li><li><span class="tocitem">Direct Usage with Optimizer Backends</span><ul><li><a class="tocitem" href="../neural_ode_galacticoptim/">Neural Ordinary Differential Equations with GalacticOptim.jl</a></li><li><a class="tocitem" href="../neural_ode_flux/">Neural Ordinary Differential Equations with Flux.train!</a></li></ul></li><li><span class="tocitem">Training Techniques</span><ul><li><a class="tocitem" href="../multiple_shooting/">Multiple Shooting</a></li><li><a class="tocitem" href="../local_minima/">Strategies to Avoid Local Minima</a></li><li><a class="tocitem" href="../prediction_error_method/">Prediction error method (PEM)</a></li><li><a class="tocitem" href="../divergence/">Handling Divergent and Unstable Trajectories</a></li><li><a class="tocitem" href="../multiple_nn/">Simultaneous Fitting of Multiple Neural Networks</a></li><li><a class="tocitem" href="../data_parallel/">Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching</a></li><li><a class="tocitem" href="../second_order_neural/">Neural Second Order Ordinary Differential Equation</a></li><li><a class="tocitem" href="../second_order_adjoints/">Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis</a></li><li><a class="tocitem" href="../minibatch/">Training a Neural Ordinary Differential Equation with Mini-Batching</a></li></ul></li><li><span class="tocitem">Stochastic Differential Equation (SDE) Tutorials</span><ul><li><a class="tocitem" href="../optimization_sde/">Optimization of Stochastic Differential Equations</a></li><li><a class="tocitem" href="../neural_sde/">Neural Stochastic Differential Equations</a></li></ul></li><li><span class="tocitem">Delay Differential Equation (DDE) Tutorials</span><ul><li><a class="tocitem" href="../delay_diffeq/">Delay Differential Equations</a></li></ul></li><li><span class="tocitem">Differential-Algebraic Equation (DAE) Tutorials</span><ul><li><a class="tocitem" href="../physical_constraints/">Enforcing Physical Constraints via Universal Differential-Algebraic Equations</a></li></ul></li><li><span class="tocitem">Partial Differential Equation (PDE) Tutorials</span><ul><li><a class="tocitem" href="../pde_constrained/">Partial Differential Equation (PDE) Constrained Optimization</a></li></ul></li><li><span class="tocitem">Hybrid and Jump Equation Tutorials</span><ul><li><a class="tocitem" href="../hybrid_diffeq/">Training Neural Networks in Hybrid Differential Equations</a></li><li><a class="tocitem" href="../bouncing_ball/">Bouncing Ball Hybrid ODE Optimization</a></li><li><a class="tocitem" href="../jump/">Neural Jump Diffusions (Neural Jump SDE) and Neural Partial Differential Equations (Neural PDEs)</a></li></ul></li><li><span class="tocitem">Bayesian Estimation Tutorials</span><ul><li><a class="tocitem" href="../turing_bayesian/">Bayesian Estimation of Differential Equations with Probabilistic Programming</a></li><li><a class="tocitem" href="../BayesianNODE_NUTS/">Bayesian Neural ODEs: NUTS</a></li><li><a class="tocitem" href="../BayesianNODE_SGLD/">Bayesian Neural ODEs: SGLD</a></li></ul></li><li><span class="tocitem">Optimal and Model Predictive Control Tutorials</span><ul><li><a class="tocitem" href="../optimal_control/">Solving Optimal Control Problems with Universal Differential Equations</a></li><li><a class="tocitem" href="../feedback_control/">Universal Differential Equations for Neural Feedback Control</a></li><li><a class="tocitem" href="../SDE_control/">Controlling Stochastic Differential Equations</a></li></ul></li><li><span class="tocitem">Universal Differential Equations and Physical Layer Tutorials</span><ul><li><a class="tocitem" href="../universal_diffeq/">Universal Ordinary, Stochastic, and Partial Differential Equation Examples</a></li><li><a class="tocitem" href="../tensor_layer/">Physics Informed Machine Learning with TensorLayer</a></li><li><a class="tocitem" href="../hamiltonian_nn/">Hamiltonian Neural Network</a></li></ul></li><li><span class="tocitem">Layer APIs</span><ul><li><a class="tocitem" href="../../layers/BasisLayers/">Classical Basis Layers</a></li><li><a class="tocitem" href="../../layers/TensorLayer/">Tensor Product Layer</a></li><li><a class="tocitem" href="../../layers/CNFLayer/">Continuous Normalizing Flows Layer</a></li><li><a class="tocitem" href="../../layers/SplineLayer/">Spline Layer</a></li><li><a class="tocitem" href="../../layers/NeuralDELayers/">Neural Differential Equation Layers</a></li><li><a class="tocitem" href="../../layers/HamiltonianNN/">Hamiltonian Neural Network Layer</a></li></ul></li><li><span class="tocitem">Manual and APIs</span><ul><li><a class="tocitem" href="../../ControllingAdjoints/">Controlling Choices of Adjoints</a></li><li><a class="tocitem" href="../../Flux/">Use with Flux Chain and train!</a></li><li><a class="tocitem" href="../../FastChain/">FastChain</a></li><li><a class="tocitem" href="../../Collocation/">Smoothed Collocation</a></li><li><a class="tocitem" href="../../GPUs/">GPUs</a></li><li><a class="tocitem" href="../../sciml_train/">sciml_train and GalacticOptim.jl</a></li></ul></li><li><a class="tocitem" href="../../Benchmark/">Benchmarks</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Ordinary Differential Equation (ODE) Tutorials</a></li><li class="is-active"><a href>Optimization of Ordinary Differential Equations</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Optimization of Ordinary Differential Equations</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/DiffEqFlux.jl/blob/master/docs/src/examples/optimization_ode.md" title="Edit on GitHub"><span class="docs-icon fab">ï</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Optimization-of-Ordinary-Differential-Equations"><a class="docs-heading-anchor" href="#Optimization-of-Ordinary-Differential-Equations">Optimization of Ordinary Differential Equations</a><a id="Optimization-of-Ordinary-Differential-Equations-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-of-Ordinary-Differential-Equations" title="Permalink"></a></h1><h2 id="Copy-Paste-Code"><a class="docs-heading-anchor" href="#Copy-Paste-Code">Copy-Paste Code</a><a id="Copy-Paste-Code-1"></a><a class="docs-heading-anchor-permalink" href="#Copy-Paste-Code" title="Permalink"></a></h2><p>If you want to just get things running, try the following! Explanation will follow.</p><pre><code class="language-julia hljs">using DifferentialEquations, DiffEqFlux, Plots

function lotka_volterra!(du, u, p, t)
  x, y = u
  Î±, Î², Î´, Î³ = p
  du[1] = dx = Î±*x - Î²*x*y
  du[2] = dy = -Î´*y + Î³*x*y
end

# Initial condition
u0 = [1.0, 1.0]

# Simulation interval and intermediary points
tspan = (0.0, 10.0)
tsteps = 0.0:0.1:10.0

# LV equation parameter. p = [Î±, Î², Î´, Î³]
p = [1.5, 1.0, 3.0, 1.0]

# Setup the ODE problem, then solve
prob = ODEProblem(lotka_volterra!, u0, tspan, p)
sol = solve(prob, Tsit5())

# Plot the solution
using Plots
plot(sol)
savefig(&quot;LV_ode.png&quot;)

function loss(p)
  sol = solve(prob, Tsit5(), p=p, saveat = tsteps)
  loss = sum(abs2, sol.-1)
  return loss, sol
end

callback = function (p, l, pred)
  display(l)
  plt = plot(pred, ylim = (0, 6))
  display(plt)
  # Tell sciml_train to not halt the optimization. If return true, then
  # optimization stops.
  return false
end

result_ode = DiffEqFlux.sciml_train(loss, p,
                                    cb = callback,
                                    maxiters = 100)
# result_ode = DiffEqFlux.sciml_train(loss, p, ADAM(0.1), cb = callback)</code></pre><h2 id="Explanation"><a class="docs-heading-anchor" href="#Explanation">Explanation</a><a id="Explanation-1"></a><a class="docs-heading-anchor-permalink" href="#Explanation" title="Permalink"></a></h2><p>First let&#39;s create a Lotka-Volterra ODE using DifferentialEquations.jl. For more details, <a href="http://docs.juliadiffeq.org/dev/">see the DifferentialEquations.jl documentation</a>. The Lotka-Volterra equations have the form:</p><p class="math-container">\[\begin{aligned}
\frac{dx}{dt} &amp;= \alpha x - \beta x y      \\
\frac{dy}{dt} &amp;= -\delta y + \gamma x y    \\
\end{aligned}\]</p><pre><code class="language-julia hljs">using DifferentialEquations, DiffEqFlux, Plots

function lotka_volterra!(du, u, p, t)
  x, y = u
  Î±, Î², Î´, Î³ = p
  du[1] = dx = Î±*x - Î²*x*y
  du[2] = dy = -Î´*y + Î³*x*y
end

# Initial condition
u0 = [1.0, 1.0]

# Simulation interval and intermediary points
tspan = (0.0, 10.0)
tsteps = 0.0:0.1:10.0

# LV equation parameter. p = [Î±, Î², Î´, Î³]
p = [1.5, 1.0, 3.0, 1.0]

# Setup the ODE problem, then solve
prob = ODEProblem(lotka_volterra!, u0, tspan, p)
sol = solve(prob, Tsit5())

# Plot the solution
using Plots
plot(sol)
savefig(&quot;LV_ode.png&quot;)</code></pre><p><img src="https://user-images.githubusercontent.com/1814174/51388169-9a07f300-1af6-11e9-8c6c-83c41e81d11c.png" alt="LV Solution Plot"/></p><p>For this first example, we do not yet include a neural network. We take <a href="https://docs.juliadiffeq.org/latest/analysis/sensitivity/">AD-compatible <code>solve</code> function</a> function that takes the parameters and an initial condition and returns the solution of the differential equation. Next we choose a loss function. Our goal will be to find parameters that make the Lotka-Volterra solution constant <code>x(t)=1</code>, so we define our loss as the squared distance from 1. Note that when using <code>sciml_train</code>, the first return is the loss value, and the other returns are sent to the callback for monitoring convergence.</p><pre><code class="language-julia hljs">function loss(p)
  sol = solve(prob, Tsit5(), p=p, saveat = tsteps)
  loss = sum(abs2, sol.-1)
  return loss, sol
end</code></pre><p>Lastly, we use the <code>sciml_train</code> function to train the parameters using <code>ADAM</code> to arrive at parameters which optimize for our goal. <code>sciml_train</code> allows defining a callback that will be called at each step of our training loop. It takes in the current parameter vector and the returns of the last call to the loss function. We will display the current loss and make a plot of the current situation:</p><pre><code class="language-julia hljs">callback = function (p, l, pred)
  display(l)
  plt = plot(pred, ylim = (0, 6))
  display(plt)
  # Tell sciml_train to not halt the optimization. If return true, then
  # optimization stops.
  return false
end</code></pre><p>Let&#39;s optimize the model.</p><pre><code class="language-julia hljs">result_ode = DiffEqFlux.sciml_train(loss, p, cb = callback)</code></pre><p>In just seconds we found parameters which give a relative loss of <code>1e-16</code>! We can get the final loss with <code>result_ode.minimum</code>, and get the optimal parameters with <code>result_ode.u</code>. For example, we can plot the final outcome and show that we solved the control problem and successfully found parameters to make the ODE solution constant:</p><pre><code class="language-julia hljs">remade_solution = solve(remake(prob, p = result_ode.u), Tsit5(),      
                        saveat = tsteps)
plot(remade_solution, ylim = (0, 6))</code></pre><p><img src="https://user-images.githubusercontent.com/1814174/51399500-1f4dd080-1b14-11e9-8c9d-144f93b6eac2.gif" alt="Final plot"/></p><p>Note that this was done with the default optimizer. One can also pass an optimization method, like <code>ADAM(0.1)</code>, and tweak settings like set <code>maxiters=100</code> to force at most 100 iterations of the optimization. This looks like:</p><pre><code class="language-julia hljs">result_ode = DiffEqFlux.sciml_train(loss, p, ADAM(0.1), cb = callback, maxiters=100)</code></pre><p>For more information on tweaking this functionality, see the <a href="../../sciml_train/#sciml_train">sciml_train</a> documentation</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">Â« DiffEqFlux.jl: Generalized Physics-Informed and Scientific Machine Learning (SciML)</a><a class="docs-footer-nextpage" href="../stiff_ode_fit/">Parameter Estimation on Highly Stiff Systems Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.16 on <span class="colophon-date" title="Tuesday 3 May 2022 13:08">Tuesday 3 May 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
