<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Weather forecasting with neural ODEs · DiffEqFlux.jl</title><meta name="title" content="Weather forecasting with neural ODEs · DiffEqFlux.jl"/><meta property="og:title" content="Weather forecasting with neural ODEs · DiffEqFlux.jl"/><meta property="twitter:title" content="Weather forecasting with neural ODEs · DiffEqFlux.jl"/><meta name="description" content="Documentation for DiffEqFlux.jl."/><meta property="og:description" content="Documentation for DiffEqFlux.jl."/><meta property="twitter:description" content="Documentation for DiffEqFlux.jl."/><meta property="og:url" content="https://docs.sciml.ai/DiffEqFlux/stable/examples/neural_ode_weather_forecast/"/><meta property="twitter:url" content="https://docs.sciml.ai/DiffEqFlux/stable/examples/neural_ode_weather_forecast/"/><link rel="canonical" href="https://docs.sciml.ai/DiffEqFlux/stable/examples/neural_ode_weather_forecast/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="DiffEqFlux.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">DiffEqFlux.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures</a></li><li><span class="tocitem">Differential Equation Machine Learning Tutorials</span><ul><li><a class="tocitem" href="../neural_ode/">Neural Ordinary Differential Equations</a></li><li><a class="tocitem" href="../GPUs/">Neural ODEs on GPUs</a></li><li><a class="tocitem" href="../mnist_neural_ode/">GPU-based MNIST Neural ODE Classifier</a></li><li><a class="tocitem" href="../mnist_conv_neural_ode/">Convolutional Neural ODE MNIST Classifier on GPU</a></li><li><a class="tocitem" href="../augmented_neural_ode/">Augmented Neural Ordinary Differential Equations</a></li><li><a class="tocitem" href="../neural_sde/">Neural Stochastic Differential Equations With Method of Moments</a></li><li><a class="tocitem" href="../collocation/">Smoothed Collocation for Fast Two-Stage Training</a></li><li><a class="tocitem" href="../normalizing_flows/">Continuous Normalizing Flows</a></li><li><a class="tocitem" href="../hamiltonian_nn/">Hamiltonian Neural Network</a></li><li><a class="tocitem" href="../tensor_layer/">Physics-Informed Machine Learning (PIML) with TensorLayer</a></li><li><a class="tocitem" href="../multiple_shooting/">Multiple Shooting</a></li><li class="is-active"><a class="tocitem" href>Weather forecasting with neural ODEs</a><ul class="internal"><li><a class="tocitem" href="#The-data"><span>The data</span></a></li></ul></li></ul></li><li><span class="tocitem">Layer APIs</span><ul><li><a class="tocitem" href="../../layers/BasisLayers/">Classical Basis Layers</a></li><li><a class="tocitem" href="../../layers/TensorLayer/">Tensor Product Layer</a></li><li><a class="tocitem" href="../../layers/CNFLayer/">Continuous Normalizing Flows Layer</a></li><li><a class="tocitem" href="../../layers/SplineLayer/">Spline Layer</a></li><li><a class="tocitem" href="../../layers/NeuralDELayers/">Neural Differential Equation Layers</a></li><li><a class="tocitem" href="../../layers/HamiltonianNN/">Hamiltonian Neural Network Layer</a></li></ul></li><li><span class="tocitem">Utility Function APIs</span><ul><li><a class="tocitem" href="../../utilities/Collocation/">Smoothed Collocation</a></li><li><a class="tocitem" href="../../utilities/MultipleShooting/">Multiple Shooting Functionality</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Differential Equation Machine Learning Tutorials</a></li><li class="is-active"><a href>Weather forecasting with neural ODEs</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Weather forecasting with neural ODEs</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/DiffEqFlux.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/DiffEqFlux.jl/blob/master/docs/src/examples/neural_ode_weather_forecast.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Weather-forecasting-with-neural-ODEs"><a class="docs-heading-anchor" href="#Weather-forecasting-with-neural-ODEs">Weather forecasting with neural ODEs</a><a id="Weather-forecasting-with-neural-ODEs-1"></a><a class="docs-heading-anchor-permalink" href="#Weather-forecasting-with-neural-ODEs" title="Permalink"></a></h1><p>In this example we are going to apply neural ODEs to a multidimensional weather dataset and use it for weather forecasting. This example is adapted from <a href="https://sebastiancallh.github.io/post/neural-ode-weather-forecast/">Forecasting the weather with neural ODEs - Sebatian Callh personal blog</a>.</p><h2 id="The-data"><a class="docs-heading-anchor" href="#The-data">The data</a><a id="The-data-1"></a><a class="docs-heading-anchor-permalink" href="#The-data" title="Permalink"></a></h2><p>The data is a four-dimensional dataset of daily temperature, humidity, wind speed and pressure measured over four years in the city Delhi. Let us download and plot it.</p><pre><code class="language-julia hljs">using Random, Dates, Optimization, ComponentArrays, Lux, OptimizationOptimisers, DiffEqFlux,
    OrdinaryDiffEq, CSV, DataFrames, Dates, Statistics, Plots, DataDeps

function download_data(data_url = &quot;https://raw.githubusercontent.com/SebastianCallh/neural-ode-weather-forecast/master/data/&quot;,
        data_local_path = &quot;./delhi&quot;)
    function load(file_name)
        data_dep = DataDep(&quot;delhi/train&quot;, &quot;&quot;, &quot;$data_url/$file_name&quot;)
        Base.download(data_dep, data_local_path; i_accept_the_terms_of_use = true)
        CSV.read(joinpath(data_local_path, file_name), DataFrame)
    end

    train_df = load(&quot;DailyDelhiClimateTrain.csv&quot;)
    test_df = load(&quot;DailyDelhiClimateTest.csv&quot;)
    return vcat(train_df, test_df)
end

df = download_data()</code></pre><div><div style = "float: left;"><span>5×5 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">date</th><th style = "text-align: left;">meantemp</th><th style = "text-align: left;">humidity</th><th style = "text-align: left;">wind_speed</th><th style = "text-align: left;">meanpressure</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "Dates.Date" style = "text-align: left;">Date</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">2013-01-01</td><td style = "text-align: right;">10.0</td><td style = "text-align: right;">84.5</td><td style = "text-align: right;">0.0</td><td style = "text-align: right;">1015.67</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">2013-01-02</td><td style = "text-align: right;">7.4</td><td style = "text-align: right;">92.0</td><td style = "text-align: right;">2.98</td><td style = "text-align: right;">1017.8</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: left;">2013-01-03</td><td style = "text-align: right;">7.16667</td><td style = "text-align: right;">87.0</td><td style = "text-align: right;">4.63333</td><td style = "text-align: right;">1018.67</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">4</td><td style = "text-align: left;">2013-01-04</td><td style = "text-align: right;">8.66667</td><td style = "text-align: right;">71.3333</td><td style = "text-align: right;">1.23333</td><td style = "text-align: right;">1017.17</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">5</td><td style = "text-align: left;">2013-01-05</td><td style = "text-align: right;">6.0</td><td style = "text-align: right;">86.8333</td><td style = "text-align: right;">3.7</td><td style = "text-align: right;">1016.5</td></tr></tbody></table></div><pre><code class="language-julia hljs">FEATURES = [:meantemp, :humidity, :wind_speed, :meanpressure]
UNITS = [&quot;Celsius&quot;, &quot;g/m³ of water&quot;, &quot;km/h&quot;, &quot;hPa&quot;]
FEATURE_NAMES = [&quot;Mean temperature&quot;, &quot;Humidity&quot;, &quot;Wind speed&quot;, &quot;Mean pressure&quot;]

function plot_data(df)
    plots = map(enumerate(zip(FEATURES, FEATURE_NAMES, UNITS))) do (i, (f, n, u))
        plot(df[:, :date], df[:, f]; title = n, label = nothing,
            ylabel = u, size = (800, 600), color = i)
    end

    n = length(plots)
    plot(plots...; layout = (Int(n / 2), Int(n / 2)))
end

plot_data(df)</code></pre><img src="ad5d5b06.svg" alt="Example block output"/><p>The data show clear annual behaviour (it is difficult to see for pressure due to wild measurement errors but the pattern is there). It is concievable that this system can be described with an ODE, but which? Let us use an network to learn the dynamics from the dataset. Training neural networks is easier with standardised data so we will compute standardised features before training. Finally, we take the first 20 days for training and the rest for testing.</p><pre><code class="language-julia hljs">function standardize(x)
    μ = mean(x; dims = 2)
    σ = std(x; dims = 2)
    z = (x .- μ) ./ σ
    return z, μ, σ
end

function featurize(raw_df, num_train = 20)
    raw_df.year = Float64.(year.(raw_df.date))
    raw_df.month = Float64.(month.(raw_df.date))
    df = combine(groupby(raw_df, [:year, :month]),
        :date =&gt; (d -&gt; mean(year.(d)) .+ mean(month.(d)) ./ 12),
        :meantemp =&gt; mean,
        :humidity =&gt; mean,
        :wind_speed =&gt; mean,
        :meanpressure =&gt; mean;
        renamecols = false)
    t_and_y(df) = df.date&#39;, Matrix(select(df, FEATURES))&#39;
    t_train, y_train = t_and_y(df[1:num_train, :])
    t_test, y_test = t_and_y(df[(num_train + 1):end, :])
    t_train, t_mean, t_scale = standardize(t_train)
    y_train, y_mean, y_scale = standardize(y_train)
    t_test = (t_test .- t_mean) ./ t_scale
    y_test = (y_test .- y_mean) ./ y_scale

    return (vec(t_train), y_train,
        vec(t_test), y_test,
        (t_mean, t_scale),
        (y_mean, y_scale))
end

function plot_features(t_train, y_train, t_test, y_test)
    plt_split = plot(reshape(t_train, :), y_train&#39;;
        linewidth = 3, colors = 1:4,
        xlabel = &quot;Normalized time&quot;,
        ylabel = &quot;Normalized values&quot;,
        label = nothing,
        title = &quot;Features&quot;)
    plot!(plt_split, reshape(t_test, :), y_test&#39;;
        linewidth = 3, linestyle = :dash,
        color = [1 2 3 4], label = nothing)
    plot!(plt_split, [0], [0]; linewidth = 0,
        label = &quot;Train&quot;, color = 1)
    plot!(plt_split, [0], [0]; linewidth = 0,
        linestyle = :dash, label = &quot;Test&quot;,
        color = 1,
        ylims = (-5, 5))
end

t_train, y_train, t_test, y_test, (t_mean, t_scale), (y_mean, y_scale) = featurize(df)
plot_features(t_train, y_train, t_test, y_test)</code></pre><img src="edfe21b8.svg" alt="Example block output"/><p>The dataset is now centered around 0 with a standard deviation of 1. We will ignore the extreme pressure measurements for simplicity. Since they are in the test split they won&#39;t impact training anyway. We are now ready to construct and train our model! To avoid local minimas we will train iteratively with increasing amounts of data.</p><pre><code class="language-julia hljs">function neural_ode(t, data_dim)
    f = Chain(Dense(data_dim =&gt; 64, swish), Dense(64 =&gt; 32, swish), Dense(32 =&gt; data_dim))

    node = NeuralODE(f, extrema(t), Tsit5(); saveat = t,
        abstol = 1e-9, reltol = 1e-9)

    rng = Random.default_rng()
    p, state = Lux.setup(rng, f)

    return node, ComponentArray(p), state
end

function train_one_round(node, p, state, y, opt, maxiters, rng, y0 = y[:, 1]; kwargs...)
    predict(p) = Array(node(y0, p, state)[1])
    loss(p) = sum(abs2, predict(p) .- y)

    adtype = Optimization.AutoZygote()
    optf = OptimizationFunction((p, _) -&gt; loss(p), adtype)
    optprob = OptimizationProblem(optf, p)
    res = solve(optprob, opt; maxiters = maxiters, kwargs...)
    res.minimizer, state
end

function train(t, y, obs_grid, maxiters, lr, rng, p = nothing, state = nothing; kwargs...)
    log_results(ps, losses) = (p, loss) -&gt; begin
        push!(ps, copy(p))
        push!(losses, loss)
        false
    end

    ps, losses = ComponentArray[], Float32[]
    for k in obs_grid
        node, p_new, state_new = neural_ode(t, size(y, 1))
        p === nothing &amp;&amp; (p = p_new)
        state === nothing &amp;&amp; (state = state_new)

        p, state = train_one_round(node, p, state, y, AdamW(lr), maxiters, rng;
            callback = log_results(ps, losses), kwargs...)
    end
    ps, state, losses
end

rng = MersenneTwister(123)
obs_grid = 4:4:length(t_train) # we train on an increasing amount of the first k obs
maxiters = 150
lr = 5e-3
ps, state, losses = train(t_train, y_train, obs_grid, maxiters, lr, rng; progress = true)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(ComponentArrays.ComponentArray[(layer_1 = (weight = Float32[-0.19882827 0.14599217 -0.0768421 -0.05357114; 0.04744517 -0.0895702 0.016537454 -0.20737658; … ; -0.12927154 0.109002285 0.27685302 0.10130692; 0.11791332 -0.006846112 -0.009305438 0.25198746], bias = Float32[0.0; 0.0; … ; 0.0; 0.0;;]), layer_2 = (weight = Float32[0.07421538 0.19287288 … 6.246567f-5 0.18907869; 0.0014761686 0.06823793 … -0.21505547 0.24160132; … ; 0.10664564 -0.1304743 … 0.16833296 -0.20709324; 0.014347017 -0.17500323 … 0.008982807 -0.15172452], bias = Float32[0.0; 0.0; … ; 0.0; 0.0;;]), layer_3 = (weight = Float32[0.3139254 0.17675175 … -0.09646406 -0.29894128; -0.28109372 -0.38429087 … 0.29709685 -0.3670575; -0.2770275 0.26380146 … -0.05768143 0.36777768; -0.131739 -0.22656956 … 0.34814408 0.25094345], bias = Float32[0.0; 0.0; 0.0; 0.0;;])), (layer_1 = (weight = Float32[-0.20382826 0.15099217 -0.0818421 -0.04857114; 0.04244517 -0.0845702 0.011537454 -0.20237659; … ; -0.124271534 0.10400228 0.28185302 0.09630692; 0.11291332 -0.0018461118 -0.014305438 0.25698745], bias = Float32[0.005; 0.005; … ; -0.0050000004; 0.005;;]), layer_2 = (weight = Float32[0.079215385 0.18787289 … 0.005062465 0.19407868; 0.0064761685 0.06323793 … -0.21005547 0.24660131; … ; 0.10164564 -0.1254743 … 0.16333297 -0.21209323; 0.019347016 -0.18000323 … 0.013982808 -0.14672452], bias = Float32[0.005; 0.005; … ; -0.0049999994; 0.0050000004;;]), layer_3 = (weight = Float32[0.31892538 0.17175175 … -0.09146406 -0.2939413; -0.2860937 -0.37929088 … 0.29209685 -0.3720575; -0.2720275 0.25880146 … -0.05268143 0.37277767; -0.136739 -0.22156957 … 0.3431441 0.24594346], bias = Float32[0.005; -0.005; 0.005; -0.005;;])), (layer_1 = (weight = Float32[-0.20869814 0.15577698 -0.08678692 -0.043705225; 0.0374541 -0.079619445 0.0065308935 -0.19738707; … ; -0.11965542 0.0995043 0.28659484 0.09169843; 0.10863839 0.0023325533 -0.01873007 0.26125854], bias = Float32[0.009938955; 0.010006713; … ; -0.009726935; 0.0094261505;;]), layer_2 = (weight = Float32[0.08393831 0.18320647 … 0.009086836 0.19890507; 0.011314158 0.058445882 … -0.20592637 0.25152266; … ; 0.0970181 -0.12090433 … 0.1593937 -0.21683332; 0.0242579 -0.18487625 … 0.018260507 -0.1417492], bias = Float32[0.009793041; 0.009902911; … ; -0.009712176; 0.009953663;;]), layer_3 = (weight = Float32[0.32392082 0.16714321 … -0.09043119 -0.28905004; -0.29109886 -0.3748129 … 0.29074928 -0.37684968; -0.26716533 0.25393832 … -0.05251495 0.3777824; -0.14173527 -0.2169766 … 0.34203574 0.24106322], bias = Float32[0.009846954; -0.009732971; 0.009996066; -0.009839969;;])), (layer_1 = (weight = Float32[-0.2133498 0.16024435 -0.091605835 -0.039055698; 0.03252205 -0.07480999 0.0015263385 -0.19245495; … ; -0.11549749 0.095552355 0.29098284 0.087547004; 0.105343044 0.005563909 -0.022192594 0.264559], bias = Float32[0.0147586595; 0.015014771; … ; -0.014107037; 0.012947455;;]), layer_2 = (weight = Float32[0.08824667 0.17902702 … 0.012145167 0.20342097; 0.015909707 0.053973354 … -0.2028766 0.25630662; … ; 0.09282282 -0.11683504 … 0.15642276 -0.22124735; 0.029032 -0.18954498 … 0.021361364 -0.13682182], bias = Float32[0.014237091; 0.01465091; … ; -0.014074684; 0.01484719;;]), layer_3 = (weight = Float32[0.32891434 0.1630889 … -0.0916922 -0.2843289; -0.2960049 -0.37099043 … 0.29134518 -0.38132155; -0.26226747 0.24939078 … -0.05499275 0.38278776; -0.14673643 -0.21292701 … 0.34327164 0.23633829], bias = Float32[0.014462981; -0.014083077; 0.014974169; -0.014470845;;])), (layer_1 = (weight = Float32[-0.21772827 0.1643508 -0.096229665 -0.034678; 0.027682954 -0.070195995 -0.003454206 -0.18761295; … ; -0.11178721 0.0920985 0.29498568 0.08384155; 0.10310432 0.007894531 -0.024424313 0.26680702], bias = Float32[0.019399486; 0.020011362; … ; -0.018119749; 0.015291974;;]), layer_2 = (weight = Float32[0.09207099 0.17538369 … 0.014534452 0.20749785; 0.020211887 0.04988724 … -0.20076084 0.26088357; … ; 0.089056194 -0.11325452 … 0.15417002 -0.22529611; 0.033615053 -0.19392344 … 0.023184624 -0.13199434], bias = Float32[0.018216943; 0.0191893; … ; -0.01806809; 0.019654876;;]), layer_3 = (weight = Float32[0.33383906 0.15961197 … -0.093957916 -0.2798253; -0.30062422 -0.36778092 … 0.29264528 -0.38536912; -0.25731683 0.24532844 … -0.05846908 0.3877853; -0.15169866 -0.20944287 … 0.34558442 0.23179328], bias = Float32[0.018796131; -0.017972773; 0.019918; -0.018860433;;])), (layer_1 = (weight = Float32[-0.22181706 0.16810647 -0.10061016 -0.030591216; 0.022957152 -0.065797925 -0.008386018 -0.18288173; … ; -0.10847955 0.08906921 0.29861233 0.08053818; 0.10180553 0.0094804 -0.025471624 0.26811203], bias = Float32[0.023814505; 0.024982113; … ; -0.021775909; 0.01644428;;]), layer_2 = (weight = Float32[0.095405616 0.17224242 … 0.016533313 0.21106714; 0.024200354 0.046203714 … -0.19932695 0.26519644; … ; 0.08568641 -0.110113785 … 0.15241744 -0.22896957; 0.037955638 -0.19794157 … 0.023951111 -0.12733795], bias = Float32[0.021669263; 0.023474919; … ; -0.021696448; 0.024342343;;]), layer_3 = (weight = Float32[0.3386287 0.15665746 … -0.09667951 -0.27556473; -0.30476362 -0.36506617 … 0.29401872 -0.38892204; -0.2523251 0.24187526 … -0.062441405 0.3927633; -0.1565798 -0.20648172 … 0.3484335 0.22743598], bias = Float32[0.022818226; -0.021368904; 0.024807047; -0.022991154;;])), (layer_1 = (weight = Float32[-0.22562853 0.17155069 -0.10472781 -0.02678525; 0.01835848 -0.06161469 -0.01324178 -0.17827582; … ; -0.10552197 0.08639403 0.30189145 0.07758525; 0.10124477 0.010497848 -0.025579622 0.26867262], bias = Float32[0.027977008; 0.029909309; … ; -0.025101222; 0.016596442;;]), layer_2 = (weight = Float32[0.09828887 0.16952994 … 0.018323256 0.21413338; 0.02787805 0.042903185 … -0.19835487 0.26921257; … ; 0.082671344 -0.10735336 … 0.15100953 -0.23228157; 0.04201253 -0.20156087 … 0.023964906 -0.122927144], bias = Float32[0.024588251; 0.027479816; … ; -0.024977192; 0.028870216;;]), layer_3 = (weight = Float32[0.34323642 0.15414645 … -0.09958357 -0.27155295; -0.30829218 -0.36272296 … 0.29511735 -0.39195314; -0.24731742 0.23908214 … -0.06669164 0.39770624; -0.16135013 -0.20397916 … 0.3515553 0.22326143], bias = Float32[0.026520712; -0.024278225; 0.029616255; -0.026857221;;])), (layer_1 = (weight = Float32[-0.22919054 0.17473087 -0.108588114 -0.023233516; 0.013898706 -0.057634827 -0.017991694 -0.1738081; … ; -0.10286506 0.08401356 0.3048589 0.07493386; 0.101219825 0.0111006275 -0.025020488 0.26869103], bias = Float32[0.03188107; 0.03477037; … ; -0.028126838; 0.015997997;;]), layer_2 = (weight = Float32[0.100781985 0.16716637 … 0.019998409 0.21675369; 0.031262305 0.03994858 … -0.19768539 0.27292356; … ; 0.079967685 -0.10491623 … 0.14984246 -0.23526034; 0.04575796 -0.20477602 … 0.023493953 -0.11882501], bias = Float32[0.02701449; 0.03119142; … ; -0.027934931; 0.03319722;;]), layer_3 = (weight = Float32[0.34764034 0.15200475 … -0.10252425 -0.26777962; -0.31117508 -0.36065206 … 0.29578862 -0.3944771; -0.2423283 0.23692901 … -0.07108881 0.40259346; -0.16599183 -0.20187142 … 0.35480425 0.21925822], bias = Float32[0.02991028; -0.026736747; 0.03431604; -0.030460756;;])), (layer_1 = (weight = Float32[-0.23253609 0.1776911 -0.11221245 -0.01990347; 0.009589728 -0.053844634 -0.022604693 -0.16949199; … ; -0.100466006 0.08187999 0.3075508 0.072541386; 0.10155829 0.011411482 -0.024025872 0.26834133], bias = Float32[0.035537403; 0.03953736; … ; -0.030884225; 0.014875773;;]), layer_2 = (weight = Float32[0.10295346 0.16508125 … 0.021592785 0.21900846; 0.034377627 0.03729825 … -0.19721274 0.27633893; … ; 0.07753508 -0.10275281 … 0.14884904 -0.23794033; 0.049178217 -0.2076077 … 0.0227479 -0.11507309], bias = Float32[0.029016526; 0.034610473; … ; -0.030597636; 0.037283894;;]), layer_3 = (weight = Float32[0.35184067 0.150173 … -0.105429344 -0.26422313; -0.31346005 -0.35878378 … 0.29601884 -0.396541; -0.23739871 0.23534758 … -0.07553438 0.4073988; -0.17049538 -0.20010324 … 0.3580947 0.21541327], bias = Float32[0.033004172; -0.02879794; 0.038873155; -0.033808764;;])), (layer_1 = (weight = Float32[-0.23569706 0.18046817 -0.11562914 -0.01676305; 0.0054441392 -0.050232954 -0.027050659 -0.16534181; … ; -0.09828888 0.079955295 0.31000042 0.07037195; 0.10212116 0.011526012 -0.022779092 0.26776448], bias = Float32[0.03896761; 0.0441777; … ; -0.03340258; 0.013416292;;]), layer_2 = (weight = Float32[0.10486985 0.16321875 … 0.023105605 0.22097968; 0.037251033 0.03491279 … -0.19687083 0.27947882; … ; 0.07533766 -0.10082191 … 0.1479867 -0.2403567; 0.052272532 -0.21009257 … 0.02188298 -0.11168792], bias = Float32[0.030674387; 0.037747998; … ; -0.032994345; 0.04109647;;]), layer_3 = (weight = Float32[0.35585275 0.14860728 … -0.10827196 -0.26085538; -0.3152423 -0.35707432 … 0.29587236 -0.39821187; -0.23257273 0.23424697 … -0.07994518 0.41209137; -0.17485625 -0.19862872 … 0.36137506 0.2117144], bias = Float32[0.03582599; -0.030523032; 0.043252468; -0.036911264;;]))  …  (layer_1 = (weight = Float32[-0.3123258 0.041014623 -0.035465565 -0.0030230142; -0.11170576 0.129467 -0.38264966 -0.116319105; … ; -0.07028036 0.07898457 0.50002646 0.2557283; 0.075467564 -0.441334 0.3099467 0.37351593], bias = Float32[0.16708541; 0.105060875; … ; 0.1646648; 0.11325805;;]), layer_2 = (weight = Float32[0.13806309 -0.3402771 … 0.3345373 0.3620465; -0.055689983 -0.12945983 … -0.11258115 0.3206997; … ; 0.15397343 -0.10064204 … -0.0846711 -0.3187544; 0.15234531 -0.18696408 … -0.12127346 -0.076211184], bias = Float32[0.15782785; 0.06631242; … ; -0.17669076; -0.020295978;;]), layer_3 = (weight = Float32[0.36152577 0.073355235 … -0.07077326 -0.23959346; -0.62703454 -0.43671116 … 0.4563349 -0.29555067; -0.11782268 0.27225175 … -0.14776444 0.6308359; -0.20382018 0.019770687 … 0.42047474 0.17326806], bias = Float32[0.08334865; -0.11538043; -0.05118416; -0.10359817;;])), (layer_1 = (weight = Float32[-0.3123249 0.040957544 -0.035686888 -0.0029900155; -0.111707 0.1291829 -0.38289756 -0.11627158; … ; -0.07033621 0.07908325 0.5000666 0.2557367; 0.07539886 -0.441475 0.31013092 0.37359628], bias = Float32[0.16713333; 0.105124444; … ; 0.16472845; 0.11299147;;]), layer_2 = (weight = Float32[0.13812685 -0.34006166 … 0.33456013 0.3620475; -0.0556908 -0.12945703 … -0.11257233 0.3207761; … ; 0.15403527 -0.100633584 … -0.08453248 -0.31895435; 0.15232614 -0.1869588 … -0.12128959 -0.07623547], bias = Float32[0.1578734; 0.06634565; … ; -0.17670503; -0.020289192;;]), layer_3 = (weight = Float32[0.36150092 0.07334379 … -0.07077294 -0.23955631; -0.6270815 -0.43669066 … 0.45649907 -0.2955052; -0.11775822 0.27228594 … -0.14781433 0.63085365; -0.20371233 0.019827835 … 0.4203736 0.17323326], bias = Float32[0.08344165; -0.11543357; -0.05122506; -0.10354402;;])), (layer_1 = (weight = Float32[-0.31232524 0.040901307 -0.035910077 -0.002955655; -0.11170685 0.1288968 -0.38314533 -0.11622524; … ; -0.07039233 0.07918115 0.50010824 0.255745; 0.075328834 -0.44161734 0.31031728 0.3736775], bias = Float32[0.1671825; 0.10518733; … ; 0.16479366; 0.11272227;;]), layer_2 = (weight = Float32[0.13819213 -0.3398462 … 0.33458427 0.3620494; -0.055690292 -0.12945291 … -0.11256249 0.32085183; … ; 0.15409581 -0.10062644 … -0.08439451 -0.31915578; 0.15230854 -0.18695202 … -0.12130394 -0.076261476], bias = Float32[0.15792027; 0.066379465; … ; -0.17672072; -0.020280855;;]), layer_3 = (weight = Float32[0.361477 0.073333584 … -0.07077133 -0.23952077; -0.6271291 -0.43666896 … 0.45666456 -0.29546127; -0.117692925 0.27231976 … -0.1478662 0.63087296; -0.20360549 0.01988375 … 0.42027104 0.17319974], bias = Float32[0.08353443; -0.11548798; -0.05126628; -0.10348937;;])), (layer_1 = (weight = Float32[-0.3123259 0.04084298 -0.036133867 -0.0029205347; -0.11170643 0.12861021 -0.3833956 -0.116178796; … ; -0.07044557 0.079278804 0.50015116 0.25574976; 0.075258896 -0.44176337 0.31050774 0.3737582], bias = Float32[0.16723204; 0.10525102; … ; 0.16485903; 0.11245391;;]), layer_2 = (weight = Float32[0.1382578 -0.33963048 … 0.33460873 0.3620515; -0.05568851 -0.12944867 … -0.11255012 0.32093027; … ; 0.15415663 -0.100618325 … -0.08425954 -0.3193613; 0.15229213 -0.18694465 … -0.12131515 -0.07628705], bias = Float32[0.1579676; 0.066416144; … ; -0.17673638; -0.020271316;;]), layer_3 = (weight = Float32[0.36145186 0.07332305 … -0.07076671 -0.23948708; -0.62717974 -0.43664908 … 0.45683166 -0.29541838; -0.11762433 0.2723566 … -0.1479195 0.63089305; -0.20349666 0.01994043 … 0.4201663 0.17316741], bias = Float32[0.08362496; -0.11554273; -0.05130558; -0.10343401;;])), (layer_1 = (weight = Float32[-0.31232527 0.04078162 -0.036356818 -0.002886276; -0.1117072 0.12832408 -0.38364854 -0.1161308; … ; -0.07049516 0.079377525 0.50019383 0.25575018; 0.07519022 -0.44191208 0.31070068 0.37383726], bias = Float32[0.16728036; 0.105316535; … ; 0.16492286; 0.112186916;;]), layer_2 = (weight = Float32[0.1383222 -0.33941364 … 0.33463183 0.36205223; -0.05568684 -0.12944534 … -0.11253661 0.32101163; … ; 0.15421927 -0.10060802 … -0.08412635 -0.31957024; 0.15227525 -0.18693821 … -0.12132496 -0.076310806], bias = Float32[0.15801379; 0.06645473; … ; -0.17675072; -0.02026213;;]), layer_3 = (weight = Float32[0.3614242 0.07331067 … -0.070759915 -0.2394535; -0.6272325 -0.43663168 … 0.45699912 -0.29537493; -0.11755325 0.27239645 … -0.14797264 0.6309122; -0.20338488 0.019999426 … 0.42006055 0.17313462], bias = Float32[0.08371293; -0.115596354; -0.05134212; -0.103379056;;])), (layer_1 = (weight = Float32[-0.31232285 0.0407187 -0.0365788 -0.002853624; -0.11170943 0.12803794 -0.3839023 -0.116081156; … ; -0.07054297 0.079477906 0.5002353 0.2557482; 0.07512257 -0.44206086 0.31089345 0.3739149], bias = Float32[0.16732699; 0.10538345; … ; 0.16498496; 0.11191915;;]), layer_2 = (weight = Float32[0.13838498 -0.339195 … 0.33465305 0.36205107; -0.055686235 -0.12944283 … -0.112524085 0.3210936; … ; 0.15428373 -0.100596346 … -0.0839923 -0.31978017; 0.15225694 -0.18693316 … -0.12133561 -0.076333255], bias = Float32[0.15805832; 0.06649289; … ; -0.17676389; -0.020254163;;]), layer_3 = (weight = Float32[0.36139455 0.0732965 … -0.07075283 -0.2394186; -0.62728465 -0.436615 … 0.45716578 -0.2953301; -0.117482066 0.27243686 … -0.14802489 0.6309298; -0.2032716 0.020060379 … 0.41995522 0.17310031], bias = Float32[0.08379945; -0.11564845; -0.051376756; -0.10332541;;])), (layer_1 = (weight = Float32[-0.3123199 0.040656667 -0.036801245 -0.00282152; -0.1117117 0.12775029 -0.38415483 -0.1160314; … ; -0.070591725 0.0795791 0.5002763 0.25574675; 0.07505441 -0.44220814 0.3110851 0.37399262], bias = Float32[0.1673732; 0.1054502; … ; 0.16504695; 0.111647844;;]), layer_2 = (weight = Float32[0.13844766 -0.33897492 … 0.3346738 0.3620491; -0.055686083 -0.12943988 … -0.11251302 0.3211737; … ; 0.15434827 -0.100585476 … -0.08385615 -0.3199894; 0.15223815 -0.18692823 … -0.12134737 -0.07635646], bias = Float32[0.15810242; 0.066529445; … ; -0.17677748; -0.020246536;;]), layer_3 = (weight = Float32[0.36136493 0.07328226 … -0.07074635 -0.23938291; -0.6273349 -0.43659657 … 0.45733193 -0.29528493; -0.117412135 0.2724755 … -0.14807725 0.6309472; -0.20315935 0.020121232 … 0.41985047 0.17306519], bias = Float32[0.083886065; -0.115700305; -0.051411115; -0.10327261;;])), (layer_1 = (weight = Float32[-0.31231815 0.040597 -0.03702574 -0.002788294; -0.111712314 0.1274598 -0.3844053 -0.115983225; … ; -0.070643 0.07967979 0.5003183 0.2557475; 0.07498418 -0.44235417 0.3112767 0.37407196], bias = Float32[0.16742072; 0.10551541; … ; 0.16511074; 0.11137153;;]), layer_2 = (weight = Float32[0.13851209 -0.33875424 … 0.3346959 0.36204794; -0.055685006 -0.12943526 … -0.11250231 0.32125112; … ; 0.154411 -0.10057707 … -0.083718516 -0.320198; 0.1522206 -0.18692173 … -0.12135878 -0.07638222], bias = Float32[0.15814781; 0.0665649; … ; -0.17679298; -0.02023766;;]), layer_3 = (weight = Float32[0.36133713 0.073269755 … -0.070740014 -0.23934801; -0.62738377 -0.4365751 … 0.45749873 -0.29524112; -0.117343105 0.2725118 … -0.14813139 0.630966; -0.2030496 0.020180093 … 0.4197453 0.1730309], bias = Float32[0.08397381; -0.11575358; -0.05144623; -0.10321925;;])), (layer_1 = (weight = Float32[-0.31231785 0.04053921 -0.037252396 -0.002753584; -0.11171104 0.12716652 -0.38465428 -0.115936816; … ; -0.07069634 0.079779655 0.5003617 0.25574997; 0.07491178 -0.44249985 0.3114692 0.374153], bias = Float32[0.16746987; 0.10557913; … ; 0.16517659; 0.11109055;;]), layer_2 = (weight = Float32[0.13857856 -0.3385333 … 0.33471975 0.36204794; -0.055682547 -0.12942891 … -0.11249109 0.32132667; … ; 0.15447186 -0.1005709 … -0.083580315 -0.3204068; 0.15220477 -0.1869134 … -0.121368945 -0.07641046], bias = Float32[0.15819481; 0.066600144; … ; -0.17681019; -0.020227116;;]), layer_3 = (weight = Float32[0.36131117 0.07325915 … -0.07073313 -0.23931447; -0.6274322 -0.43655118 … 0.4576667 -0.29519904; -0.1172741 0.27254656 … -0.14818768 0.6309867; -0.20294175 0.020237025 … 0.4196391 0.17299803], bias = Float32[0.084062986; -0.11580852; -0.051481858; -0.10316451;;])), (layer_1 = (weight = Float32[-0.31231785 0.04053921 -0.037252396 -0.002753584; -0.11171104 0.12716652 -0.38465428 -0.115936816; … ; -0.07069634 0.079779655 0.5003617 0.25574997; 0.07491178 -0.44249985 0.3114692 0.374153], bias = Float32[0.16746987; 0.10557913; … ; 0.16517659; 0.11109055;;]), layer_2 = (weight = Float32[0.13857856 -0.3385333 … 0.33471975 0.36204794; -0.055682547 -0.12942891 … -0.11249109 0.32132667; … ; 0.15447186 -0.1005709 … -0.083580315 -0.3204068; 0.15220477 -0.1869134 … -0.121368945 -0.07641046], bias = Float32[0.15819481; 0.066600144; … ; -0.17681019; -0.020227116;;]), layer_3 = (weight = Float32[0.36131117 0.07325915 … -0.07073313 -0.23931447; -0.6274322 -0.43655118 … 0.4576667 -0.29519904; -0.1172741 0.27254656 … -0.14818768 0.6309867; -0.20294175 0.020237025 … 0.4196391 0.17299803], bias = Float32[0.084062986; -0.11580852; -0.051481858; -0.10316451;;]))], (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple()), Float32[207.64261, 160.30783, 133.90874, 118.0531, 107.915215, 101.012596, 96.00739, 92.17459, 89.12211, 86.63203  …  4.789423, 4.7864623, 4.783505, 4.780546, 4.7775817, 4.774612, 4.7716465, 4.7686768, 4.7656984, 4.7656984])</code></pre><p>We can now animate the training to get a better understanding of the fit.</p><pre><code class="language-julia hljs">predict(y0, t, p, state) = begin
    node, _, _ = neural_ode(t, length(y0))
    Array(node(y0, p, state)[1])
end

function plot_pred(t_train, y_train, t_grid, rescale_t, rescale_y, num_iters, p, state,
        loss, y0 = y_train[:, 1])
    y_pred = predict(y0, t_grid, p, state)
    return plot_result(rescale_t(t_train), rescale_y(y_train), rescale_t(t_grid),
        rescale_y(y_pred), loss, num_iters)
end

function plot_pred(t, y, y_pred)
    plt = Plots.scatter(t, y; label = &quot;Observation&quot;)
    Plots.plot!(plt, t, y_pred; label = &quot;Prediction&quot;)
end

function plot_pred(t, y, t_pred, y_pred; kwargs...)
    plot_params = zip(eachrow(y), eachrow(y_pred), FEATURE_NAMES, UNITS)
    map(enumerate(plot_params)) do (i, (yᵢ, ŷᵢ, name, unit))
        plt = Plots.plot(t_pred, ŷᵢ; label = &quot;Prediction&quot;, color = i, linewidth = 3,
            legend = nothing, title = name, kwargs...)
        Plots.scatter!(plt, t, yᵢ; label = &quot;Observation&quot;, xlabel = &quot;Time&quot;, ylabel = unit,
            markersize = 5, color = i)
    end
end

function plot_result(t, y, t_pred, y_pred, loss, num_iters; kwargs...)
    plts_preds = plot_pred(t, y, t_pred, y_pred; kwargs...)
    plot!(plts_preds[1]; ylim = (10, 40), legend = (0.65, 1.0))
    plot!(plts_preds[2]; ylim = (20, 100))
    plot!(plts_preds[3]; ylim = (2, 12))
    plot!(plts_preds[4]; ylim = (990, 1025))

    p_loss = Plots.plot(loss; label = nothing, linewidth = 3,
        title = &quot;Loss&quot;, xlabel = &quot;Iterations&quot;, xlim = (0, num_iters))
    plots = [plts_preds..., p_loss]
    plot(plots...; layout = grid(length(plots), 1), size = (900, 900))
end

function animate_training(plot_frame, t_train, y_train, ps, losses, obs_grid;
        pause_for = 300)
    obs_count = Dict(i - 1 =&gt; n for (i, n) in enumerate(obs_grid))
    is = [min(i, length(losses)) for i in 2:(length(losses) + pause_for)]
    @animate for i in is
        stage = Int(floor((i - 1) / length(losses) * length(obs_grid)))
        k = obs_count[stage]
        plot_frame(t_train[1:k], y_train[:, 1:k], ps[i], losses[1:i])
    end every 2
end

num_iters = length(losses)
t_train_grid = collect(range(extrema(t_train)...; length = 500))
rescale_t(x) = t_scale .* x .+ t_mean
rescale_y(x) = y_scale .* x .+ y_mean
function plot_frame(t, y, p, loss)
    plot_pred(t, y, t_train_grid, rescale_t, rescale_y, num_iters, p, state, loss)
end
anim = animate_training(plot_frame, t_train, y_train, ps, losses, obs_grid)
gif(anim, &quot;node_weather_forecast_training.gif&quot;)</code></pre><img src="e82854ba.gif" alt="Example block output"/><p>Looks good! But how well does the model forecast?</p><pre><code class="language-julia hljs">function plot_extrapolation(t_train, y_train, t_test, y_test, t̂, ŷ)
    plts = plot_pred(t_train, y_train, t̂, ŷ)
    for (i, (plt, y)) in enumerate(zip(plts, eachrow(y_test)))
        scatter!(plt, t_test, y; color = i, markerstrokecolor = :white,
            label = &quot;Test observation&quot;)
    end

    plot!(plts[1]; ylim = (10, 40), legend = :topleft)
    plot!(plts[2]; ylim = (20, 100))
    plot!(plts[3]; ylim = (2, 12))
    plot!(plts[4]; ylim = (990, 1025))
    plot(plts...; layout = grid(length(plts), 1), size = (900, 900))
end

t_grid = collect(range(minimum(t_train), maximum(t_test); length = 500))
y_pred = predict(y_train[:, 1], t_grid, ps[end], state)
plot_extrapolation(rescale_t(t_train), rescale_y(y_train), rescale_t(t_test),
    rescale_y(y_test), rescale_t(t_grid), rescale_y(y_pred))</code></pre><img src="5f61d0dd.svg" alt="Example block output"/><p>While there is some drift in the weather patterns, the model extrapolates very well!</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../multiple_shooting/">« Multiple Shooting</a><a class="docs-footer-nextpage" href="../../layers/BasisLayers/">Classical Basis Layers »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Sunday 24 December 2023 23:29">Sunday 24 December 2023</span>. Using Julia version 1.10.0-rc3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
