<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Neural Differential Equation Layers · DiffEqFlux.jl</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-90474609-3"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-90474609-3', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://diffeqflux.sciml.ai/stable/layers/NeuralDELayers/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="DiffEqFlux.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">DiffEqFlux.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures</a></li><li><span class="tocitem">Differential Equation Machine Learning Tutorials</span><ul><li><a class="tocitem" href="../../examples/neural_ode/">Neural Ordinary Differential Equations</a></li><li><a class="tocitem" href="../../examples/GPUs/">Neural ODEs on GPUs</a></li><li><a class="tocitem" href="../../examples/mnist_neural_ode/">GPU-based MNIST Neural ODE Classifier</a></li><li><a class="tocitem" href="../../examples/mnist_conv_neural_ode/">Convolutional Neural ODE MNIST Classifier on GPU</a></li><li><a class="tocitem" href="../../examples/augmented_neural_ode/">Augmented Neural Ordinary Differential Equations</a></li><li><a class="tocitem" href="../../examples/neural_sde/">Neural Stochastic Differential Equations With Method of Moments</a></li><li><a class="tocitem" href="../../examples/collocation/">Smoothed Collocation for Fast Two-Stage Training</a></li><li><a class="tocitem" href="../../examples/normalizing_flows/">Continuous Normalizing Flows</a></li><li><a class="tocitem" href="../../examples/hamiltonian_nn/">Hamiltonian Neural Network</a></li><li><a class="tocitem" href="../../examples/tensor_layer/">Physics-Informed Machine Learning (PIML) with TensorLayer</a></li><li><a class="tocitem" href="../../examples/multiple_shooting/">Multiple Shooting</a></li></ul></li><li><span class="tocitem">Layer APIs</span><ul><li><a class="tocitem" href="../BasisLayers/">Classical Basis Layers</a></li><li><a class="tocitem" href="../TensorLayer/">Tensor Product Layer</a></li><li><a class="tocitem" href="../CNFLayer/">Continuous Normalizing Flows Layer</a></li><li><a class="tocitem" href="../SplineLayer/">Spline Layer</a></li><li class="is-active"><a class="tocitem" href>Neural Differential Equation Layers</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Helper-Layer-Functions"><span>Helper Layer Functions</span></a></li></ul></li><li><a class="tocitem" href="../HamiltonianNN/">Hamiltonian Neural Network Layer</a></li></ul></li><li><span class="tocitem">Utility Function APIs</span><ul><li><a class="tocitem" href="../../utilities/Collocation/">Smoothed Collocation</a></li><li><a class="tocitem" href="../../utilities/MultipleShooting/">Multiple Shooting Functionality</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Layer APIs</a></li><li class="is-active"><a href>Neural Differential Equation Layers</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Neural Differential Equation Layers</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/DiffEqFlux.jl/blob/master/docs/src/layers/NeuralDELayers.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Neural-Differential-Equation-Layer-Functions"><a class="docs-heading-anchor" href="#Neural-Differential-Equation-Layer-Functions">Neural Differential Equation Layer Functions</a><a id="Neural-Differential-Equation-Layer-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-Differential-Equation-Layer-Functions" title="Permalink"></a></h1><p>The following layers are helper functions for easily building neural differential equation architectures in the currently most efficient way. As demonstrated in the tutorials, they do not have to be used since automatic differentiation will just work over <code>solve</code>, but these cover common use cases and choose what&#39;s known to be the optimal mode of AD for the respective equation type.</p><article class="docstring"><header><a class="docstring-binding" id="DiffEqFlux.NeuralODE" href="#DiffEqFlux.NeuralODE"><code>DiffEqFlux.NeuralODE</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Constructs a continuous-time recurrant neural network, also known as a neural ordinary differential equation (neural ODE), with a fast gradient calculation via adjoints [1]. At a high level this corresponds to solving the forward differential equation, using a second differential equation that propagates the derivatives of the loss backwards in time.</p><pre><code class="language-julia hljs">NeuralODE(model,tspan,alg=nothing,args...;kwargs...)
NeuralODE(model::FastChain,tspan,alg=nothing,args...;
          sensealg=InterpolatingAdjoint(autojacvec=SciMLSensitivity.ReverseDiffVJP(true)),
          kwargs...)</code></pre><p>Arguments:</p><ul><li><code>model</code>: A Chain or FastChain neural network that defines the ̇x.</li><li><code>tspan</code>: The timespan to be solved on.</li><li><code>alg</code>: The algorithm used to solve the ODE. Defaults to <code>nothing</code>, i.e. the default algorithm from DifferentialEquations.jl.</li><li><code>sensealg</code>: The choice of differentiation algorthm used in the backpropogation. Defaults to an adjoint method, and with <code>FastChain</code> it defaults to utilizing a tape-compiled ReverseDiff vector-Jacobian product for extra efficiency. Seee the <a href="https://diffeq.sciml.ai/dev/analysis/sensitivity/">Local Sensitivity Analysis</a> documentation for more details.</li><li><code>kwargs</code>: Additional arguments splatted to the ODE solver. See the <a href="https://diffeq.sciml.ai/dev/basics/common_solver_opts/">Common Solver Arguments</a> documentation for more details.</li></ul><p>References:</p><p>[1] Pontryagin, Lev Semenovich. Mathematical theory of optimal processes. CRC press, 1987.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DiffEqFlux.jl/blob/fa96a1f3e28c7d2e2cbe65ca2268cb590820c1d8/src/neural_de.jl#L5-L38">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiffEqFlux.NeuralDSDE" href="#DiffEqFlux.NeuralDSDE"><code>DiffEqFlux.NeuralDSDE</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Constructs a neural stochastic differential equation (neural SDE) with diagonal noise.</p><pre><code class="language-julia hljs">NeuralDSDE(model1,model2,tspan,alg=nothing,args...;
           sensealg=TrackerAdjoint(),kwargs...)
NeuralDSDE(model1::FastChain,model2::FastChain,tspan,alg=nothing,args...;
           sensealg=TrackerAdjoint(),kwargs...)</code></pre><p>Arguments:</p><ul><li><code>model1</code>: A Chain or FastChain neural network that defines the drift function.</li><li><code>model2</code>: A Chain or FastChain neural network that defines the diffusion function. Should output a vector of the same size as the input.</li><li><code>tspan</code>: The timespan to be solved on.</li><li><code>alg</code>: The algorithm used to solve the ODE. Defaults to <code>nothing</code>, i.e. the default algorithm from DifferentialEquations.jl.</li><li><code>sensealg</code>: The choice of differentiation algorthm used in the backpropogation. Defaults to using reverse-mode automatic differentiation via Tracker.jl</li><li><code>kwargs</code>: Additional arguments splatted to the ODE solver. See the <a href="https://diffeq.sciml.ai/dev/basics/common_solver_opts/">Common Solver Arguments</a> documentation for more details.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DiffEqFlux.jl/blob/fa96a1f3e28c7d2e2cbe65ca2268cb590820c1d8/src/neural_de.jl#L103-L127">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiffEqFlux.NeuralSDE" href="#DiffEqFlux.NeuralSDE"><code>DiffEqFlux.NeuralSDE</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Constructs a neural stochastic differential equation (neural SDE).</p><pre><code class="language-julia hljs">NeuralSDE(model1,model2,tspan,nbrown,alg=nothing,args...;
          sensealg=TrackerAdjoint(),kwargs...)
NeuralSDE(model1::FastChain,model2::FastChain,tspan,nbrown,alg=nothing,args...;
          sensealg=TrackerAdjoint(),kwargs...)</code></pre><p>Arguments:</p><ul><li><code>model1</code>: A Chain or FastChain neural network that defines the drift function.</li><li><code>model2</code>: A Chain or FastChain neural network that defines the diffusion function. Should output a matrix that is nbrown x size(x,1).</li><li><code>tspan</code>: The timespan to be solved on.</li><li><code>nbrown</code>: The number of Brownian processes</li><li><code>alg</code>: The algorithm used to solve the ODE. Defaults to <code>nothing</code>, i.e. the default algorithm from DifferentialEquations.jl.</li><li><code>sensealg</code>: The choice of differentiation algorthm used in the backpropogation. Defaults to using reverse-mode automatic differentiation via Tracker.jl</li><li><code>kwargs</code>: Additional arguments splatted to the ODE solver. See the <a href="https://diffeq.sciml.ai/dev/basics/common_solver_opts/">Common Solver Arguments</a> documentation for more details.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DiffEqFlux.jl/blob/fa96a1f3e28c7d2e2cbe65ca2268cb590820c1d8/src/neural_de.jl#L215-L240">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiffEqFlux.NeuralCDDE" href="#DiffEqFlux.NeuralCDDE"><code>DiffEqFlux.NeuralCDDE</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Constructs a neural delay differential equation (neural DDE) with constant delays.</p><pre><code class="language-julia hljs">NeuralCDDE(model,tspan,hist,lags,alg=nothing,args...;
          sensealg=TrackerAdjoint(),kwargs...)
NeuralCDDE(model::FastChain,tspan,hist,lags,alg=nothing,args...;
          sensealg=TrackerAdjoint(),kwargs...)</code></pre><p>Arguments:</p><ul><li><code>model</code>: A Chain or FastChain neural network that defines the derivative function. Should take an input of size <code>[x;x(t-lag_1);...;x(t-lag_n)]</code> and produce and output shaped like <code>x</code>.</li><li><code>tspan</code>: The timespan to be solved on.</li><li><code>hist</code>: Defines the history function <code>h(t)</code> for values before the start of the integration.</li><li><code>lags</code>: Defines the lagged values that should be utilized in the neural network.</li><li><code>alg</code>: The algorithm used to solve the ODE. Defaults to <code>nothing</code>, i.e. the default algorithm from DifferentialEquations.jl.</li><li><code>sensealg</code>: The choice of differentiation algorthm used in the backpropogation. Defaults to using reverse-mode automatic differentiation via Tracker.jl</li><li><code>kwargs</code>: Additional arguments splatted to the ODE solver. See the <a href="https://diffeq.sciml.ai/dev/basics/common_solver_opts/">Common Solver Arguments</a> documentation for more details.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DiffEqFlux.jl/blob/fa96a1f3e28c7d2e2cbe65ca2268cb590820c1d8/src/neural_de.jl#L327-L355">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiffEqFlux.NeuralDAE" href="#DiffEqFlux.NeuralDAE"><code>DiffEqFlux.NeuralDAE</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Constructs a neural differential-algebraic equation (neural DAE).</p><pre><code class="language-julia hljs">NeuralDAE(model,constraints_model,tspan,alg=nothing,args...;
          sensealg=TrackerAdjoint(),kwargs...)
NeuralDAE(model::FastChain,constraints_model,tspan,alg=nothing,args...;
          sensealg=TrackerAdjoint(),kwargs...)</code></pre><p>Arguments:</p><ul><li><code>model</code>: A Chain or FastChain neural network that defines the derivative function. Should take an input of size <code>x</code> and produce the residual of <code>f(dx,x,t)</code> for only the differential variables.</li><li><code>constraints_model</code>: A function <code>constraints_model(u,p,t)</code> for the fixed constaints to impose on the algebraic equations.</li><li><code>tspan</code>: The timespan to be solved on.</li><li><code>alg</code>: The algorithm used to solve the ODE. Defaults to <code>nothing</code>, i.e. the default algorithm from DifferentialEquations.jl.</li><li><code>sensealg</code>: The choice of differentiation algorthm used in the backpropogation. Defaults to using reverse-mode automatic differentiation via Tracker.jl</li><li><code>kwargs</code>: Additional arguments splatted to the ODE solver. See the <a href="https://diffeq.sciml.ai/dev/basics/common_solver_opts/">Common Solver Arguments</a> documentation for more details.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DiffEqFlux.jl/blob/fa96a1f3e28c7d2e2cbe65ca2268cb590820c1d8/src/neural_de.jl#L404-L430">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiffEqFlux.NeuralODEMM" href="#DiffEqFlux.NeuralODEMM"><code>DiffEqFlux.NeuralODEMM</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Constructs a physically-constrained continuous-time recurrant neural network, also known as a neural differential-algebraic equation (neural DAE), with a mass matrix and a fast gradient calculation via adjoints [1]. The mass matrix formulation is:</p><p class="math-container">\[Mu&#39; = f(u,p,t)\]</p><p>where <code>M</code> is semi-explicit, i.e. singular with zeros for rows corresponding to the constraint equations.</p><pre><code class="language-julia hljs">NeuralODEMM(model,constraints_model,tspan,mass_matrix,alg=nothing,args...;kwargs...)
NeuralODEMM(model::FastChain,tspan,mass_matrix,alg=nothing,args...;
          sensealg=InterpolatingAdjoint(autojacvec=SciMLSensitivity.ReverseDiffVJP(true)),
          kwargs...)</code></pre><p>Arguments:</p><ul><li><code>model</code>: A Chain or FastChain neural network that defines the ̇<code>f(u,p,t)</code></li><li><code>constraints_model</code>: A function <code>constraints_model(u,p,t)</code> for the fixed constaints to impose on the algebraic equations.</li><li><code>tspan</code>: The timespan to be solved on.</li><li><code>mass_matrix</code>: The mass matrix associated with the DAE</li><li><code>alg</code>: The algorithm used to solve the ODE. Defaults to <code>nothing</code>, i.e. the default algorithm from DifferentialEquations.jl. This method requires an implicit ODE solver compatible with singular mass matrices. Consult the <a href="https://diffeq.sciml.ai/latest/solvers/dae_solve/">DAE solvers</a> documentation for more details.</li><li><code>sensealg</code>: The choice of differentiation algorthm used in the backpropogation. Defaults to an adjoint method, and with <code>FastChain</code> it defaults to utilizing a tape-compiled ReverseDiff vector-Jacobian product for extra efficiency. Seee the <a href="https://diffeq.sciml.ai/dev/analysis/sensitivity/">Local Sensitivity Analysis</a> documentation for more details.</li><li><code>kwargs</code>: Additional arguments splatted to the ODE solver. See the <a href="https://diffeq.sciml.ai/dev/basics/common_solver_opts/">Common Solver Arguments</a> documentation for more details.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DiffEqFlux.jl/blob/fa96a1f3e28c7d2e2cbe65ca2268cb590820c1d8/src/neural_de.jl#L477-L517">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiffEqFlux.AugmentedNDELayer" href="#DiffEqFlux.AugmentedNDELayer"><code>DiffEqFlux.AugmentedNDELayer</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Constructs an Augmented Neural Differential Equation Layer.</p><pre><code class="language-julia hljs">AugmentedNDELayer(nde, adim::Int)</code></pre><p>Arguments:</p><ul><li><code>nde</code>: Any Neural Differential Equation Layer</li><li><code>adim</code>: The number of dimensions the initial conditions should be lifted</li></ul><p>References:</p><p>[1] Dupont, Emilien, Arnaud Doucet, and Yee Whye Teh. &quot;Augmented neural ODEs.&quot; In Proceedings of the 33rd International Conference on Neural Information Processing Systems, pp. 3140-3150. 2019.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DiffEqFlux.jl/blob/fa96a1f3e28c7d2e2cbe65ca2268cb590820c1d8/src/neural_de.jl#L597-L613">source</a></section></article><h1 id="Helper-Layer-Functions"><a class="docs-heading-anchor" href="#Helper-Layer-Functions">Helper Layer Functions</a><a id="Helper-Layer-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Helper-Layer-Functions" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="DiffEqFlux.DimMover" href="#DiffEqFlux.DimMover"><code>DiffEqFlux.DimMover</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Constructs a Dimension Mover Layer.</p><pre><code class="language-julia hljs">DimMover(from, to)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DiffEqFlux.jl/blob/fa96a1f3e28c7d2e2cbe65ca2268cb590820c1d8/src/neural_de.jl#L632-L638">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiffEqFlux.FluxBatchOrder" href="#DiffEqFlux.FluxBatchOrder"><code>DiffEqFlux.FluxBatchOrder</code></a> — <span class="docstring-category">Function</span></header><section><div><p>We can have Flux&#39;s conventional order (data, channel, batch) by using it as the last layer of <code>Flux.Chain</code> to swap the batch-index and the time-index of the Neural DE&#39;s output. considering that each time point is a channel.</p><pre><code class="language-julia hljs">FluxBatchOrder = DimMover(-2, -1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DiffEqFlux.jl/blob/fa96a1f3e28c7d2e2cbe65ca2268cb590820c1d8/src/neural_de.jl#L654-L662">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../SplineLayer/">« Spline Layer</a><a class="docs-footer-nextpage" href="../HamiltonianNN/">Hamiltonian Neural Network Layer »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.22 on <span class="colophon-date" title="Thursday 11 August 2022 12:21">Thursday 11 August 2022</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
